# Properties of Asymptotic Notations

Asymptotic notations help analyze the efficiency of algorithms. The following are the key properties of Big-O (O), Omega (Œ©), and Theta (Œò) notations.

---

## 1. **Transitivity Property**

If `f(n) = O(g(n))` and `g(n) = O(h(n))`, then:

```
f(n) = O(h(n))
```

Similarly, the transitivity property applies to Œ© and Œò notations:

- If `f(n) = Œ©(g(n))` and `g(n) = Œ©(h(n))`, then `f(n) = Œ©(h(n))`.
- If `f(n) = Œò(g(n))` and `g(n) = Œò(h(n))`, then `f(n) = Œò(h(n))`.

---

## 2. **Reflexivity Property**

For any function `f(n)`, it follows that:

```
f(n) = O(f(n))
```

```
f(n) = Œ©(f(n))
```

```
f(n) = Œò(f(n))
```

This means a function is always asymptotically bounded by itself.

---

## 3. **Symmetry Property (For Theta)**

Theta notation is symmetric, meaning:

```
f(n) = Œò(g(n)) ‚áî g(n) = Œò(f(n))
```

This does **not** hold for Big-O and Omega since they define upper and lower bounds, respectively.

---

## 4. **Transposition Property**

If `f(n) = O(g(n))`, then it implies:

```
g(n) = Œ©(f(n))
```

Similarly, if `f(n) = Œò(g(n))`, then `g(n) = Œò(f(n))`.

---

## 5. **Addition Property**

If `f(n) = O(h(n))` and `g(n) = O(h(n))`, then:

```
f(n) + g(n) = O(h(n))
```

The same rule applies for Œ© and Œò notations.

Example:

```
Let f(n) = O(n¬≤) and g(n) = O(n¬≤), then:
f(n) + g(n) = O(n¬≤)
```

---

## 6. **Multiplication Property**

If `f(n) = O(g(n))` and `h(n) = O(k(n))`, then:

```
f(n) * h(n) = O(g(n) * k(n))
```

Similarly, for Œ© and Œò:

```
f(n) * h(n) = Œ©(g(n) * k(n))
```

```
f(n) * h(n) = Œò(g(n) * k(n))
```

Example:

```
If f(n) = O(n) and g(n) = O(n log n), then:
f(n) * g(n) = O(n¬≤ log n)
```

---

## 7. **Polynomial Property**

For a polynomial function `f(n) = a‚Çñn·µè + a‚Çñ‚Çã‚ÇÅn·µè‚Åª¬π + ... + a‚ÇÄ`, the asymptotic bound is determined by the highest-degree term:

```
f(n) = Œò(n·µè)
```

Example:

```
f(n) = 4n¬≥ + 2n¬≤ + 7n + 5
Œò(n¬≥)
```

---

## 8. **Logarithm Property**

Logarithms of different bases differ only by a constant factor:

```
log‚Çê n = O(log_b n)
```

Thus, base differences do not affect asymptotic complexity.

Example:

```
log‚ÇÇ n = O(log‚ÇÅ‚ÇÄ n)
```

---

## 9. **Comparability Property**

For two functions `f(n)` and `g(n)`, one of the following must be true:

```
f(n) = O(g(n)), f(n) = Œ©(g(n)), or f(n) = Œò(g(n))
```

This ensures every function has a definite asymptotic relationship.

---

## 10. **Non-Negativity Property**

Asymptotic notations are only defined for non-negative functions, meaning:

```
f(n) ‚â• 0 for sufficiently large n
```

---

## **Conclusion**

These properties help in simplifying and understanding the behavior of algorithms in terms of asymptotic analysis. Mastering these principles makes it easier to evaluate algorithm efficiency!

Would you like practical examples demonstrating these properties? üöÄ

